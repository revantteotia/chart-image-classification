{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning using VGG16 with trained weights on imagenet dataset\n",
    "#### Steps :\n",
    "1.  Removing fully connected layers for classification on top\n",
    "2.   Freezing the weights of all convulation blocks by making them untrainable\n",
    "3.   Adding fully connected layer on top of freezed convulation blocks and training them to fit our dataset\n",
    "4.   Unfreezing the top convulation block and fine-tuning it using our dataset : not needed, already getting good results by just training the fully connected layers on top\n",
    "    *   Fine-tuning only top convulation layers because lower layers learn general features (like edge, curve, etc.) while top layers learn features which are more dataset specific\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    '''\n",
    "    A function to plot train and validation loss against epochs of training\n",
    "    '''\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,max(plt.ylim())+0.5])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using ImageDataGenerator to load data from the disk\n",
    "\n",
    "\n",
    "train_val_directory_path = 'chart_images_dataset/charts/train_val'\n",
    "\n",
    "train_csv_path = 'train.csv'\n",
    "val_csv_path   = 'val.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df   = pd.read_csv(val_csv_path)\n",
    "\n",
    "IMAGE_SIZE = 224 # VGG input size\n",
    "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3) # 3 channels\n",
    "NUM_OF_CLASSES = 5\n",
    "\n",
    "\n",
    "# preprocessing the generated image batches with VGG16 preprocessing function \n",
    "# VGG16 preprocessing function : converts from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling. \n",
    "image_generator = ImageDataGenerator( preprocessing_function=tf.keras.applications.vgg16.preprocess_input  )\n",
    "\n",
    "train_data_gen = image_generator.flow_from_dataframe(\n",
    "    train_df, \n",
    "    directory=train_val_directory_path, \n",
    "    x_col='image_filename', \n",
    "    y_col='type', \n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "    color_mode='rgb', \n",
    "    class_mode='categorical', \n",
    "    batch_size=32, \n",
    "    shuffle=False, # already shuffled \n",
    "    seed=None, \n",
    "    validate_filenames=True\n",
    ")\n",
    "\n",
    "val_data_gen = image_generator.flow_from_dataframe(\n",
    "    val_df, \n",
    "    directory=train_val_directory_path, \n",
    "    x_col='image_filename', \n",
    "    y_col='type', \n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "    color_mode='rgb', \n",
    "    class_mode='categorical', \n",
    "    batch_size=32, \n",
    "    shuffle=False, # already shuffled \n",
    "    seed=None,\n",
    "    validate_filenames=True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checking/ validating some images generated by datagenerator\n",
    "\n",
    "print ('indices of categories : {}'.format(train_data_gen.class_indices))\n",
    "\n",
    "# This function will plot 4 images along with their labels.\n",
    "def plotImages(image_datas,y_list):\n",
    "    f, axarr = plt.subplots(2,2)\n",
    "    axarr[0,0].imshow(image_datas[0], cmap='gray')\n",
    "    axarr[0,0].set_title(y_list[0])\n",
    "    axarr[0,0].axis('off')\n",
    "    axarr[0,1].imshow(image_datas[1], cmap='gray')\n",
    "    axarr[0,1].set_title(y_list[1])\n",
    "    axarr[0,1].axis('off')\n",
    "    axarr[1,0].imshow(image_datas[2], cmap='gray')\n",
    "    axarr[1,0].set_title(y_list[2])\n",
    "    axarr[1,0].axis('off')\n",
    "    axarr[1,1].imshow(image_datas[3], cmap='gray')\n",
    "    axarr[1,1].set_title(y_list[3])\n",
    "    axarr[1,1].axis('off')\n",
    "\n",
    "sample_training_images, y_list = next(train_data_gen)\n",
    "sample_training_images = np.squeeze(sample_training_images) # to reduce dimension\n",
    "print(\"shape of a batch given by image data generator : {}\".format(sample_training_images.shape))\n",
    "\n",
    "plotImages(sample_training_images[:4],y_list[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading VGG16 with weights trained on imagenet dataset and w/o top classification layers \n",
    "base_VGG16 = tf.keras.applications.VGG16(input_shape=IMAGE_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_VGG16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training only top dense layers for predicting class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_VGG_based_model():\n",
    "    \n",
    "    base_VGG16.trainable = False\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        base_VGG16,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_OF_CLASSES, activation='softmax') \n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VGG_based_model = create_VGG_based_model()\n",
    "VGG_based_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "VGG_based_model_checkpoint_filepath = 'VGG_based_model/checkpoint/'\n",
    "VGG_based_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=VGG_based_model_checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=5,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "VGG_based_model_history = VGG_based_model.fit(train_data_gen, epochs=50, \n",
    "                    validation_data=val_data_gen,\n",
    "                    callbacks=[VGG_based_model_checkpoint_callback, early_stopping_callback])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitb700739b275943fe8cf709be88cb7e63",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}